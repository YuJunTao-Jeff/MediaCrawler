"""
å…³é”®è¯è§£æåŠŸèƒ½æµ‹è¯•
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

def test_keyword_splitting():
    """æµ‹è¯•å…³é”®è¯åˆ†å‰²é€»è¾‘"""
    print("=== æµ‹è¯•å…³é”®è¯åˆ†å‰²é€»è¾‘ ===")
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        "æ¾³é¹ç§‘æŠ€",  # å•ä¸ªå…³é”®è¯
        "æ¾³é¹ ç§‘æŠ€ AI",  # ç©ºæ ¼åˆ†å‰²
        "appen,æ¾³é¹,ç”°å°é¹,çˆ±æ™®æ©",  # é€—å·åˆ†å‰²
        "appen,æ¾³é¹,ç”°å°é¹,çˆ±æ™®æ©,æ¾³é¹å¤§è¿,æ¾³é¹æ— é”¡,æ¾³é¹ç§‘æŠ€,æ¾³é¹ä¸­å›½,æ¾³é¹æ•°æ®,æ¾³é¹é‡åº†",  # å®Œæ•´çš„é»˜è®¤å…³é”®è¯
        "æ¾³é¹, ç§‘æŠ€, AI",  # é€—å·+ç©ºæ ¼
        "æ¾³é¹,ç§‘æŠ€ AI,äººå·¥æ™ºèƒ½",  # æ··åˆåˆ†å‰²
        "",  # ç©ºå­—ç¬¦ä¸²
        "   ",  # åªæœ‰ç©ºæ ¼
        "æ¾³é¹,,ç§‘æŠ€",  # è¿ç»­é€—å·
    ]
    
    print("æµ‹è¯•ä¸åŒçš„å…³é”®è¯åˆ†å‰²é€»è¾‘:")
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: '{test_input}'")
        
        # å½“å‰çš„åˆ†å‰²é€»è¾‘ (ä¿®å¤åçš„ç‰ˆæœ¬)
        keywords = []
        for part in test_input.replace(',', ' ').split():
            keyword = part.strip()
            if keyword:
                keywords.append(keyword)
        
        print(f"  åˆ†å‰²ç»“æœ: {keywords}")
        print(f"  å…³é”®è¯æ•°é‡: {len(keywords)}")
        
        # æ¨¡æ‹ŸSQLæŸ¥è¯¢æ¡ä»¶
        if keywords:
            like_conditions = [f"title LIKE '%{kw}%' OR content LIKE '%{kw}%'" for kw in keywords]
            sql_condition = " OR ".join([f"({cond})" for cond in like_conditions])
            print(f"  SQLæ¡ä»¶: {sql_condition[:100]}...")
        else:
            print("  SQLæ¡ä»¶: æ— å…³é”®è¯ï¼Œä¸æ·»åŠ ç­›é€‰æ¡ä»¶")


def test_search_logic_simulation():
    """æ¨¡æ‹Ÿæœç´¢é€»è¾‘æµ‹è¯•"""
    print("\n=== æ¨¡æ‹Ÿæœç´¢é€»è¾‘æµ‹è¯• ===")
    
    # æ¨¡æ‹Ÿæ•°æ®
    mock_data = [
        {"title": "æ¾³é¹ç§‘æŠ€å‘å¸ƒAIæ–°äº§å“", "content": "æ¾³é¹ç§‘æŠ€ä»Šå¤©å‘å¸ƒäº†æœ€æ–°çš„äººå·¥æ™ºèƒ½äº§å“"},
        {"title": "appenå…¬å¸æ”¶è´­æ¡ˆä¾‹", "content": "appenå…¬å¸æœ€è¿‘å®Œæˆäº†ä¸€é¡¹é‡è¦æ”¶è´­"},
        {"title": "ç”°å°é¹è°ˆAIå‘å±•", "content": "æ¾³é¹åˆ›å§‹äººç”°å°é¹åˆ†äº«äº†å¯¹AIè¡Œä¸šçš„çœ‹æ³•"},
        {"title": "çˆ±æ™®æ©æ•°æ®æœåŠ¡", "content": "çˆ±æ™®æ©æä¾›ä¸“ä¸šçš„æ•°æ®æ ‡æ³¨æœåŠ¡"},
        {"title": "æ— å…³å†…å®¹", "content": "è¿™æ˜¯ä¸€æ¡ä¸æ¾³é¹æ— å…³çš„å†…å®¹"},
        {"title": "æ¾³é¹å¤§è¿åˆ†å…¬å¸", "content": "æ¾³é¹åœ¨å¤§è¿è®¾ç«‹äº†æ–°çš„åˆ†å…¬å¸"},
        {"title": "è…¾è®¯AIç ”ç©¶", "content": "è…¾è®¯å‘å¸ƒäº†æ–°çš„AIç ”ç©¶æˆæœ"},
    ]
    
    # æµ‹è¯•å…³é”®è¯
    test_keywords = "appen,æ¾³é¹,ç”°å°é¹,çˆ±æ™®æ©,æ¾³é¹å¤§è¿"
    
    print(f"æµ‹è¯•å…³é”®è¯: '{test_keywords}'")
    print(f"æ¨¡æ‹Ÿæ•°æ®é‡: {len(mock_data)}")
    
    # åˆ†å‰²å…³é”®è¯
    keywords = []
    for part in test_keywords.replace(',', ' ').split():
        keyword = part.strip()
        if keyword:
            keywords.append(keyword)
    
    print(f"åˆ†å‰²åçš„å…³é”®è¯: {keywords}")
    
    # æ¨¡æ‹Ÿæœç´¢
    matching_results = []
    for item in mock_data:
        matched = False
        matched_keywords = []
        
        for keyword in keywords:
            if keyword in item['title'] or keyword in item['content']:
                matched = True
                matched_keywords.append(keyword)
        
        if matched:
            matching_results.append({
                'item': item,
                'matched_keywords': matched_keywords
            })
    
    print(f"\næœç´¢ç»“æœ: {len(matching_results)} æ¡åŒ¹é…")
    for i, result in enumerate(matching_results, 1):
        item = result['item']
        matched_kw = result['matched_keywords']
        print(f"{i}. æ ‡é¢˜: {item['title']}")
        print(f"   åŒ¹é…å…³é”®è¯: {matched_kw}")
        print(f"   å†…å®¹: {item['content'][:50]}...")
        print("---")


def test_default_keywords_coverage():
    """æµ‹è¯•é»˜è®¤å…³é”®è¯è¦†ç›–åº¦"""
    print("\n=== æµ‹è¯•é»˜è®¤å…³é”®è¯è¦†ç›–åº¦ ===")
    
    default_keywords = "appen,æ¾³é¹,ç”°å°é¹,çˆ±æ™®æ©,æ¾³é¹å¤§è¿,æ¾³é¹æ— é”¡,æ¾³é¹ç§‘æŠ€,æ¾³é¹ä¸­å›½,æ¾³é¹æ•°æ®,æ¾³é¹é‡åº†"
    
    # åˆ†å‰²å…³é”®è¯
    keywords = []
    for part in default_keywords.replace(',', ' ').split():
        keyword = part.strip()
        if keyword:
            keywords.append(keyword)
    
    print(f"é»˜è®¤å…³é”®è¯åˆ—è¡¨ ({len(keywords)} ä¸ª):")
    for i, kw in enumerate(keywords, 1):
        print(f"  {i:2d}. '{kw}'")
    
    # åˆ†æå…³é”®è¯ç‰¹ç‚¹
    print(f"\nå…³é”®è¯åˆ†æ:")
    print(f"  è‹±æ–‡å…³é”®è¯: {[kw for kw in keywords if any(c.isalpha() and ord(c) < 128 for c in kw)]}")
    print(f"  ä¸­æ–‡å…³é”®è¯: {[kw for kw in keywords if any(ord(c) > 127 for c in kw)]}")
    print(f"  åŒ…å«'æ¾³é¹': {[kw for kw in keywords if 'æ¾³é¹' in kw]}")
    print(f"  åœ°åç›¸å…³: {[kw for kw in keywords if any(city in kw for city in ['å¤§è¿', 'æ— é”¡', 'é‡åº†', 'ä¸­å›½'])]}")
    
    # æ£€æŸ¥é‡å¤å’ŒåŒ…å«å…³ç³»
    duplicates = []
    for i, kw1 in enumerate(keywords):
        for j, kw2 in enumerate(keywords):
            if i != j and kw1 in kw2:
                duplicates.append((kw1, kw2))
    
    if duplicates:
        print(f"\nå‘ç°å…³é”®è¯åŒ…å«å…³ç³»:")
        for kw1, kw2 in duplicates:
            print(f"  '{kw1}' åŒ…å«åœ¨ '{kw2}' ä¸­")
    else:
        print(f"\nâœ… å…³é”®è¯ä¹‹é—´æ— åŒ…å«å…³ç³»")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å…³é”®è¯è§£æåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    test_keyword_splitting()
    test_search_logic_simulation()
    test_default_keywords_coverage()
    
    print("\n" + "=" * 50)
    print("âœ… å…³é”®è¯è§£ææµ‹è¯•å®Œæˆ")
    print("\nğŸ’¡ å»ºè®®:")
    print("  1. é»˜è®¤å…³é”®è¯åº”è¯¥æ¶µç›–æ¾³é¹ç›¸å…³çš„ä¸»è¦å˜ä½“")
    print("  2. å…³é”®è¯åˆ†å‰²é€»è¾‘åº”è¯¥æ”¯æŒé€—å·å’Œç©ºæ ¼åˆ†å‰²")
    print("  3. æœç´¢æ—¶ä½¿ç”¨ORé€»è¾‘ï¼ŒåŒ¹é…ä»»ä¸€å…³é”®è¯å³å¯")
    print("  4. æ³¨æ„å…³é”®è¯ä¹‹é—´çš„åŒ…å«å…³ç³»ï¼Œé¿å…é‡å¤åŒ¹é…")


if __name__ == "__main__":
    main()